---
title: "My title"
subtitle: "My subtitle if needed"
author: 
  - Kevin Roe
thanks: "Code and data are available at: [https://github.com/Kanghyunroe/traffic_collisions/tree/main](https://github.com/Kanghyunroe/traffic_collisions/tree/main)."
date: today
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format: pdf
number-sections: true
toc: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(here)
library(arrow)
library(ggplot2)
library(modelsummary)
library(rstanarm)
library(knitr)
library(kableExtra)


# Read in Analysis Data
analysis_data <- read_parquet(file = here("data/02-analysis_data/analysis_data.parquet"), show_col_types = FALSE)

# Read in Model Data 
prediction_model <- readRDS(file = here(
  "models/motor_fatality_prediction_model.rds"))
```


# Introduction

Automobile fatalities are a leading cause of death worldwide, posing a public health and safety concern for urban cities. For example, in 2024, thirty people have died on Toronto's roadways so far, which is a 20% increase from last year (insert citation, CBC). However, new headlines, such as CBCs, highlight that Motor Vehicle Collisions (MVC) tend to either be generalized as a summary statistic or typically fatal events are over analyzed to the extent that environmental factors surrounding the crash are ignored (CLARIFY). Moreover, general environmental factors such as the time of the crash or if a bicycle was involved in the accident are important to understand what increases the likelihood of a fatality occurring in an MVC. The use of statistical modeling on increasingly available vehicle collision data presents an opportunity to develop a nuanced understanding of what factors increases the likelihood for a fatality to occur in an accident. This paper uses the Toronto Police Service's  Annual Statistical Report from Open Data Toronto to analyze what factors are most responsible in predicting if a fatality occurs in a car crash.

The estimand of interest is the log-adjusted probability of a fatality occuring in a car crash. Specifically, we aim to quanitfy how specific environmental factors increase or decrease the likelihood of a fatality. By applying inferential analysis through Bayesian linear models, we assess not only the magnitude of these effects, but their underlying uncertainties (EDIT).

what was found (FINISH PARAGRAPH)

The paper is not only important from a public health perspective, but the paper also has policy development implications. Road safety and reducing fatal MVCs are a critical agenda item of any municipal government. The paper informs what factors increase the likelihood of death in an MVC, which informs policymakers' focus for relevant policy design. 

The remainder of this paper is structured as follows: @sec-data describes the dataset and methodology and @sec-model exhibits the use of inferential models. @Sec-results presents the results of the analysis, detailing the observed relationships between likelihood of death and various circumstantial factors. @sec-discussion discusses the broader implications and limitations of our findings.@sec-appendix presents a detailed idealized methodology to improve data collection, and additional model summary and diagnostic information.  

# Data {#sec-data}

## Overview

This dataset, "Police Annual Statistical Report - Traffic Collisions", was published and refreshed on October 21st, 2024, by the Toronto Police Service [insert citation]. The Toronto Police Service publishes various datasets on public safety and crime to inform the public about safety issues [@annual_statistics_report]. Data on traffic collisions is included in the Toronto Police Service's Annual Statistical Report, which also covers reported crimes, search of persons, firearms, and the Police Service's budget [@annual_statistics_report]. The data is collected using historical Motor Vehicle Collisions and classifies them into the following categories: 
* Property Damage (PD) Collisions
* Fail to Remain (FTR) Collisions, or commonly known as hit-and-run accidents
* Injury Collisions
* Fatalities 

Following the Municipal Freedom of Information and Protection of Privacy Act, the Toronto Police Service ensures to protect the privacy of individuals involved in the reported crimes when publishing the data. The dataset is updated annually, is open data, and can be used if an attribution statement @sec-appendix-attribution and is properly cited [@tphlicense]. 

There is an alternative dataset from the Toronto Police Service called "Motor Vehicle Collisions involving Killed or Seriously Injured Persons" (CITE). Unlike the alternative dataset, this paper's dataset focuses on all collisions, instead of only focusing on ones where someone was either killed or seriously injured. While the alternative dataset has more explanatory variables simply because more data is collected when someone dies or is seriously injured, this paper's aims to generalize if a fatality is more likely to occur based on the general circumstances surrounding a crash, such as the time of day or if property damage occurred. Thus, we ended up not going with the alternative dataset for this paper, but there are variables in the alternative dataset that may motivate future research on this subject. (EDIT TO MAKE MORE CLEAR)

The paper uses the R programming language [@citeR] to analyze the dataset. The tidyverse package was used to simulate the dataset. Also, the tidyverse [@citetidyverse], arrow [CITE] and opendatatoronto [@citeopendatatoronto] packages were used to download the Victims of Crime dataset. Then, the tidyverse [@citetidyverse] package was used to clean the raw dataset and generate tests. The testthat package [CITE THIS] was used to create tests for our cleaned dataset. Rstanarm [CITE], Arrow [CITE], and bayestestR [CITE] were used to create and test the model. Finally, ggplot2 [@citeggplot2], tidyverse [@citetidyverse], knitr [@citeknitr] and scales [@citescales] packages were used to create the tables and graphs to display the results. [edit this paragraph]

## Data Cleaning (MAYBE INCLUDE IN OTHER PLACE? )

Explain how we cleaned fatalities to a variable rather than whatever 


The variables of interest in the paper are CrimeType (named SUBTYPE in the original dataset), which categories the type of crime into the four areas of Assault, Sexual Violation, Robbery and Other; AssaultType (named ASSAULT_SUBTYPE in the original dataset), which specifies assault on peace officers into the subtypes noted in @sec-introduction; Sex (named SEX in the original dataset) - which is broken down into Male, Female and Unknown, where Unknown means the victimâ€™s sex is not known by the Toronto Police Service; and Count (named COUNT in the original dataset), which counts the number of identified victims who share the same demographic characteristics previously. Each entry in the dataset does not represent a unique person but notes the number of people who share the same characteristics, such as Sex and CrimeType. Other characteristics such as age group, reported year and age cohort were not variables of interest for the study and were removed from the cleaned dataset. Using knitr [@citeknitr], the first 10 lines of the cleaned dataset is shown in @sec-appendix-sample under @tbl-head. In addition, summaries of the Sex and Year variables are displayed in @sec-appendix-summary_statistics.  

## Measurement
	
Some paragraphs about how we go from a phenomena in the world to an entry in the dataset.

## Outcome variables

Add graphs, tables and text. Use sub-sub-headings for each outcome variable or update the subheading to be singular.

```{r}
#| label: fig-bills
#| fig-cap: Bills of penguins
#| echo: false

```

Talk more about it.

And also planes (@fig-planes). (You can change the height and width, but don't worry about doing that until you have finished every other aspect of the paper - Quarto will try to make it look nice and the defaults usually work well once you have enough text.)

```{r}
#| label: fig-planes
#| fig-cap: Relationship between wing length and width
#| echo: false
#| warning: false
#| message: false


```

Talk way more about it. 

## Predictor variables

### Hour


Add graphs, tables and text.

Use sub-sub-headings for each outcome variable and feel free to combine a few into one if they go together naturally.

### Type of Crash

### Automobile 

### Motorcycle

### Passenger

### Pedestrian

### Police Division
Fixed effects

### Year 
Fixed effects

### Interaction Terms
Why you have interaction between hour and all these things


# Model

The goal of our modelling strategy is twofold. Firstly,...

Here we briefly describe the Bayesian analysis model used to investigate... Background details and diagnostics are included in [Appendix -@sec-model-details].

## Model set-up

Define $y_i$ as the number of seconds that the plane remained aloft. Then $\beta_i$ is the wing width and $\gamma_i$ is the wing length, both measured in millimeters.  

\begin{align} 
y_i|\mu_i, \sigma &\sim \mbox{Normal}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_i + \gamma_i\\
\alpha &\sim \mbox{Normal}(0, 2.5) \\
\beta &\sim \mbox{Normal}(0, 2.5) \\
\gamma &\sim \mbox{Normal}(0, 2.5) \\
\sigma &\sim \mbox{Exponential}(1)
\end{align}

We run the model in R [@citeR] using the `rstanarm` package of @rstanarm. We use the default priors from `rstanarm`.


### Model justification

We expect a positive relationship between the size of the wings and time spent aloft. In particular...

We can use maths by including latex between dollar signs, for instance $\theta$.


# Results

Our results are summarized in @tbl-modelresults.

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

library(rstanarm)

```

```{r}
#| echo: false
#| eval: true
#| label: tbl-modelresults
#| tbl-cap: "Explanatory models of flight time based on wing width and wing length"
#| warning: false

#modelsummary::modelsummary(
 # list(
  #  "First model" = first_model
  #),
  #statistic = "mad",
  #fmt = 2
#)
```




# Discussion

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

Please don't use these as sub-heading labels - change them to be what your point actually is.

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {-}


# Additional data details

# Model details {#sec-model-details}

## Posterior predictive check

In we implement a posterior predictive check. This shows...

In we compare the posterior with the prior. This shows... 

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 2
#| fig-cap: "Examining how the model fits, and is affected by, the data"
#| fig-subcap: ["Posterior prediction check", "Comparing the posterior with the prior"]

#pp_check(first_model) +
  #theme_classic() +
 # theme(legend.position = "bottom")

#posterior_vs_prior(first_model) +
 # theme_minimal() +
  #scale_color_brewer(palette = "Set1") +
 # theme(legend.position = "bottom") +
 # coord_flip()
```

## Diagnostics

is a trace plot. It shows... This suggests...

is a Rhat plot. It shows... This suggests...

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

#plot(first_model, "trace")

#plot(first_model, "rhat")
```



\newpage


# References


